<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="gkY5k8D7Wl1o0OIVHcsMuk6wtmzy0fCaehFxDpl32aw" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="keyword"  content="">
    <link rel="shortcut icon" href="/img/favicon.ico">

    <title>
        
          Graph Embedding with Side Information - Steve Universe | Steve Universe&#39;s Blog
        
    </title>

    <link rel="canonical" href="https://nhuantdbk.github.io/graph-embedding-si/">

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS -->
    
<link rel="stylesheet" href="/css/hux-blog.min.css">


    <!-- Pygments Highlight CSS -->
    
<link rel="stylesheet" href="/css/highlight.css">


    <!-- Custom Fonts -->
    <!-- <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.3.0/css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    <!-- Hux change font-awesome CDN to qiniu -->
    <link href="https://cdn.staticfile.org/font-awesome/4.5.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 6.0.0"></head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Steve Universe</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                    </li>

                    

                        
                    

                        
                        <li>
                            <a href="/archives/">Archives</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/tags/">Tags</a>
                        </li>
                        
                    

                        
                        <li>
                            <a href="/about/">Monologue</a>
                        </li>
                        
                    
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        background-image: url('cover.png')
    }
</style>
<header class="intro-header" >
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <div class="post-heading">
                    <div class="tags">
                        
                          <a class="tag" href="/tags/#graph" title="graph">graph</a>
                        
                          <a class="tag" href="/tags/#embedding" title="embedding">embedding</a>
                        
                          <a class="tag" href="/tags/#item representation" title="item representation">item representation</a>
                        
                          <a class="tag" href="/tags/#cold start" title="cold start">cold start</a>
                        
                          <a class="tag" href="/tags/#side information" title="side information">side information</a>
                        
                          <a class="tag" href="/tags/#alibaba" title="alibaba">alibaba</a>
                        
                          <a class="tag" href="/tags/#python" title="python">python</a>
                        
                          <a class="tag" href="/tags/#jupyter notebook" title="jupyter notebook">jupyter notebook</a>
                        
                          <a class="tag" href="/tags/#pytorch" title="pytorch">pytorch</a>
                        
                    </div>
                    <h1>Graph Embedding with Side Information</h1>
                    <h2 class="subheading"></h2>
                    <span class="meta">
                        Posted by Steve Tran on
                        2022-01-26
                    </span>
                </div>
            </div>
        </div>
    </div>
</header>

<!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

    <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <div class="toc">

<!-- toc -->

<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#cold-start-recommendation-a-class-anchor-id-chapter1-a">Cold Start Recommendation <a class="anchor" id="chapter1"></a></a><ul>
<li><a href="#preparation-a-class-anchor-id-chapter1-1-a">Preparation <a class="anchor" id="chapter1_1"></a></a></li>
<li><a href="#preprocessing-a-class-anchor-id-chapter1-2-a">Preprocessing <a class="anchor" id="chapter1_2"></a></a><ul>
<li><a href="#ordinal-encoding">Ordinal Encoding</a></li>
<li><a href="#random-walk-methods">Random walk methods</a></li>
</ul>
</li>
<li><a href="#deep-dive-into-model-a-class-anchor-id-chapter1-3-a">Deep dive into model<a class="anchor" id="chapter1_3"></a></a><ul>
<li><a href="#generate-skip-gram-and-negative-sampling-for-picking-movies">Generate skip-gram and negative sampling for picking movies</a></li>
<li><a href="#weighted-skip-gram">Weighted Skip Gram</a></li>
<li><a href="#algorithm-training">Algorithm Training</a></li>
</ul>
</li>
<li><a href="#testing-model-a-class-anchor-id-chapter1-4-a">Testing model <a class="anchor" id="chapter1_4"></a></a></li>
</ul>
</li>
<li><a href="#end-note-a-class-anchor-id-chapter2-a">End Note <a class="anchor" id="chapter2"></a></a></li>
<li><a href="#reference-a-class-anchor-id-chapter3-a">Reference <a class="anchor" id="chapter3"></a></a></li>
</ul>
<!-- tocstop -->

</div>

<h1><a href="#introduction" class="header-anchor"></a><span id="introduction">Introduction</span></h1><div align="justify">

<p>This notebook is implemented based on paper Billion-scale Commodity Embedding for E-commerce Recommendation.</p>
<p>In Taobao, milion of new items are continously uploaded each hour. There are no user behaviors for these items. Learning item representation is important for matching, ranking in order to recommend these items to user. Collaborative Filtering based methods is only computed co-occurence of items in user history behavior. It is quite challenge to learn item representation with few or even no interactions.</p>
<p>Authors proposed new approach: Incorporate side-information to enhance embedding vectors, dubbed Graph Embedding with Side Information. For example, items with same brands or category should be closer in embedding space</p>
<p>Throughout the rest of this notebook, we will develop a model which incorporate side information into graph embedding and test model with new items not in the dataset to see the performance</p>
</div>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. magic for inline plot</span></span><br><span class="line"><span class="comment"># 2. magic so that the notebook will reload external python modules</span></span><br><span class="line"><span class="comment"># 3. magic to enable retina (high resolution) plots</span></span><br><span class="line"><span class="comment"># https://gist.github.com/minrk/3301035</span></span><br><span class="line"></span><br><span class="line">%matplotlib inline</span><br><span class="line">%load_ext autoreload</span><br><span class="line">%autoreload <span class="number">2</span></span><br><span class="line">%config InlineBackend.figure_format=<span class="string">&#x27;retina&#x27;</span></span><br></pre></td></tr></table></figure>

<pre><code>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> shutil</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> gc</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter, defaultdict</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader, Dataset</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Set fixed seed</span></span><br><span class="line">random_state = <span class="number">4111</span></span><br><span class="line">torch.manual_seed(random_state)</span><br><span class="line">random.seed(random_state)</span><br><span class="line">np.random.seed(random_state)</span><br></pre></td></tr></table></figure>

<h1><a href="#cold-start-recommendation" class="header-anchor"></a><span id="cold-start-recommendation">Cold Start Recommendation </span></h1><h2><a href="#preparation" class="header-anchor"></a><span id="preparation">Preparation </span></h2><p>We will use public available movielen throughout this experiment. At time of writing, dataset movielen25m is up-to-date and contains lots of samples. You can download via this <a target="_blank" rel="noopener" href="https://files.grouplens.org/datasets/movielens/ml-25m.zip">link</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># !wget https://files.grouplens.org/datasets/movielens/ml-25m.zip</span></span><br><span class="line"><span class="comment"># !unzip ml-25m.zip</span></span><br></pre></td></tr></table></figure>

<p>Given this dataset, we have few code chunks to clean and preprocess the data.</p>
<ul>
<li>The raw <code>movies.csv</code> contains movie_id, movie title and genres. We will convert movie_id into ordinal ids, lowercase and split genres into array of string</li>
<li>The raw <code>tags.csv</code> contains user_id, movie_id, tag and timestamp. We will drop null tag, convert to lowercase and aggregate tags by movie</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">df_entity = pd.read_csv(<span class="string">&quot;ml-25m/movies.csv&quot;</span>)</span><br><span class="line">df_entity[<span class="string">&quot;genres&quot;</span>] = df_entity[<span class="string">&quot;genres&quot;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> d: d.split(<span class="string">&quot;|&quot;</span>))</span><br><span class="line">df_entity.head()</span><br></pre></td></tr></table></figure>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movieId</th>
      <th>title</th>
      <th>genres</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Toy Story (1995)</td>
      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Jumanji (1995)</td>
      <td>[Adventure, Children, Fantasy]</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Grumpier Old Men (1995)</td>
      <td>[Comedy, Romance]</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Waiting to Exhale (1995)</td>
      <td>[Comedy, Drama, Romance]</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Father of the Bride Part II (1995)</td>
      <td>[Comedy]</td>
    </tr>
  </tbody>
</table>
</div>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_tag = pd.read_csv(<span class="string">&quot;ml-25m/tags.csv&quot;</span>).dropna()</span><br><span class="line">df_tag.head()</span><br></pre></td></tr></table></figure>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>userId</th>
      <th>movieId</th>
      <th>tag</th>
      <th>timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>260</td>
      <td>classic</td>
      <td>1439472355</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3</td>
      <td>260</td>
      <td>sci-fi</td>
      <td>1439472256</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>1732</td>
      <td>dark comedy</td>
      <td>1573943598</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1732</td>
      <td>great dialogue</td>
      <td>1573943604</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>7569</td>
      <td>so bad it's good</td>
      <td>1573943455</td>
    </tr>
  </tbody>
</table>
</div>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">df_agg_tag = df_tag.drop([<span class="string">&quot;userId&quot;</span>,<span class="string">&quot;timestamp&quot;</span>],axis=<span class="number">1</span>)\</span><br><span class="line">        .assign(tag=<span class="keyword">lambda</span> df: df[<span class="string">&quot;tag&quot;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> d: d.lower().lstrip().rstrip()))\</span><br><span class="line">        .groupby([<span class="string">&quot;movieId&quot;</span>])[<span class="string">&quot;tag&quot;</span>].agg(<span class="string">&quot;unique&quot;</span>).reset_index()</span><br><span class="line">df_agg_tag</span><br></pre></td></tr></table></figure>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movieId</th>
      <th>tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>[owned, imdb top 250, pixar, time travel, chil...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>[robin williams, time travel, fantasy, based o...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>[funny, best friend, duringcreditsstinger, fis...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>[based on novel or book, chick flick, divorce,...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>[aging, baby, confidence, contraception, daugh...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>45246</th>
      <td>208813</td>
      <td>[might like]</td>
    </tr>
    <tr>
      <th>45247</th>
      <td>208933</td>
      <td>[black and white, deal with the devil]</td>
    </tr>
    <tr>
      <th>45248</th>
      <td>209035</td>
      <td>[computer animation, japan, mass behavior, mas...</td>
    </tr>
    <tr>
      <th>45249</th>
      <td>209037</td>
      <td>[chameleon, computer animation, gluttony, humo...</td>
    </tr>
    <tr>
      <th>45250</th>
      <td>209063</td>
      <td>[black, education, friends schools, independen...</td>
    </tr>
  </tbody>
</table>
<p>45251 rows × 2 columns</p>
</div>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">df_movie_joint = df_entity.merge(df_agg_tag, on=[<span class="string">&quot;movieId&quot;</span>],how=<span class="string">&quot;outer&quot;</span>)</span><br><span class="line">df_movie_joint</span><br></pre></td></tr></table></figure>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movieId</th>
      <th>title</th>
      <th>genres</th>
      <th>tag</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>Toy Story (1995)</td>
      <td>[Adventure, Animation, Children, Comedy, Fantasy]</td>
      <td>[owned, imdb top 250, pixar, time travel, chil...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>Jumanji (1995)</td>
      <td>[Adventure, Children, Fantasy]</td>
      <td>[robin williams, time travel, fantasy, based o...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>Grumpier Old Men (1995)</td>
      <td>[Comedy, Romance]</td>
      <td>[funny, best friend, duringcreditsstinger, fis...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>Waiting to Exhale (1995)</td>
      <td>[Comedy, Drama, Romance]</td>
      <td>[based on novel or book, chick flick, divorce,...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>Father of the Bride Part II (1995)</td>
      <td>[Comedy]</td>
      <td>[aging, baby, confidence, contraception, daugh...</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>62418</th>
      <td>209157</td>
      <td>We (2018)</td>
      <td>[Drama]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>62419</th>
      <td>209159</td>
      <td>Window of the Soul (2001)</td>
      <td>[Documentary]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>62420</th>
      <td>209163</td>
      <td>Bad Poems (2018)</td>
      <td>[Comedy, Drama]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>62421</th>
      <td>209169</td>
      <td>A Girl Thing (2001)</td>
      <td>[(no genres listed)]</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>62422</th>
      <td>209171</td>
      <td>Women of Devil's Island (1962)</td>
      <td>[Action, Adventure, Drama]</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
<p>62423 rows × 4 columns</p>
</div>

<h2><a href="#preprocessing" class="header-anchor"></a><span id="preprocessing">Preprocessing </span></h2><h3><a href="#ordinal-encoding" class="header-anchor"></a><span id="ordinal-encoding">Ordinal Encoding</span></h3><p>We need to create custom ordinal encoder to serve our usecase. We transform list of category/ids features into ordinal ids which indicates start index, replace empty values by <unk></unk></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">OrdinalEncoder</span>():</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Convert categorical into ordinal integer ids</span></span><br><span class="line"><span class="string">        If value is not existed in vocab, it will be replaced by &lt;unk&gt; val</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,start_from=<span class="number">1</span>, unknown=<span class="number">0</span></span>):</span></span><br><span class="line">        self.vocabs = &#123;&#125;</span><br><span class="line">        self.wc = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        self.inv = []</span><br><span class="line">        self.start_from = start_from</span><br><span class="line">        self.unknown = unknown</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self, </span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.inv)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X)):</span><br><span class="line">            self.wc[X[i]] += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        X_uniq = np.unique(X)</span><br><span class="line"></span><br><span class="line">        self.inv = [<span class="number">0</span>] * (<span class="built_in">len</span>(X_uniq) + self.start_from)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> idx, item <span class="keyword">in</span> <span class="built_in">enumerate</span>(X_uniq):</span><br><span class="line">            self.vocabs[item] = self.start_from + idx</span><br><span class="line">            self.inv[self.start_from + idx] = item</span><br><span class="line">        </span><br><span class="line">        self.inv = np.array(self.inv)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">transform</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">isinstance</span>(X[<span class="number">0</span>],(<span class="built_in">list</span>,np.ndarray)):</span><br><span class="line">            res = []</span><br><span class="line">            <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X)):</span><br><span class="line">                tmp = [self.vocabs.get(item) <span class="keyword">for</span> item <span class="keyword">in</span> X[idx] <span class="keyword">if</span> item <span class="keyword">in</span> self.vocabs]</span><br><span class="line"></span><br><span class="line">                res.append(tmp)                </span><br><span class="line">            <span class="keyword">return</span> res</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> np.array([ self.vocabs.get(item, self.unknown) <span class="keyword">for</span> item <span class="keyword">in</span> X ],dtype=<span class="string">&quot;int&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit_transform</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.fit(X).transform(X)    </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">inverse_transform</span>(<span class="params">self, X</span>):</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(X) == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line">        X = np.array(X, dtype=<span class="string">&quot;int&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.inv[X]  </span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">n_classes_</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.inv)  </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">word_count_table</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> [self.wc[w] <span class="keyword">for</span> w <span class="keyword">in</span> self.inv]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MultiLabelEncoder</span>(<span class="params">OrdinalEncoder</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Convert multi-labels into ordinal ids</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span>(<span class="params">self, X: <span class="built_in">list</span></span>):</span></span><br><span class="line">        X_extend = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X)):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(X[i],(<span class="built_in">list</span>,np.ndarray)):</span><br><span class="line">                X_extend.extend(X[i])</span><br><span class="line">        </span><br><span class="line">        <span class="built_in">super</span>().fit(X_extend)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">metadata_cols = [<span class="string">&quot;genres&quot;</span>,<span class="string">&quot;tag&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">movie_encoder = OrdinalEncoder(start_from=<span class="number">1</span>).fit(df_movie_joint[<span class="string">&quot;movieId&quot;</span>].tolist())</span><br><span class="line">encoder_mapper = &#123;col: MultiLabelEncoder(start_from=<span class="number">1</span>).fit(df_movie_joint[col].tolist()) <span class="keyword">for</span> col <span class="keyword">in</span> metadata_cols&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">df_movie_joint_encoder = df_movie_joint[[<span class="string">&quot;movieId&quot;</span>]].copy(deep=<span class="literal">True</span>)</span><br><span class="line">df_movie_joint_encoder[<span class="string">&quot;movieId&quot;</span>] = movie_encoder.transform(df_movie_joint[<span class="string">&quot;movieId&quot;</span>].tolist())</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> metadata_cols:</span><br><span class="line">    df_movie_joint_encoder[col] = encoder_mapper[col].transform(df_movie_joint[col].fillna(<span class="string">&quot;&quot;</span>).tolist())</span><br><span class="line">    </span><br><span class="line">df_movie_joint_encoder[<span class="string">&quot;movieId&quot;</span>] = df_movie_joint_encoder[<span class="string">&quot;movieId&quot;</span>].astype(<span class="string">&quot;int&quot;</span>)</span><br><span class="line">movie_metadata_info = df_movie_joint_encoder.set_index([<span class="string">&quot;movieId&quot;</span>])[metadata_cols].to_dict(orient=<span class="string">&quot;index&quot;</span>)</span><br><span class="line"></span><br><span class="line">df_movie_joint_encoder[<span class="string">&quot;title&quot;</span>] = df_movie_joint[<span class="string">&quot;title&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_movie_joint_encoder</span><br></pre></td></tr></table></figure>

<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>movieId</th>
      <th>genres</th>
      <th>tag</th>
      <th>title</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>[3, 4, 5, 6, 10]</td>
      <td>[42617, 27920, 44422, 58453, 10932, 12378, 225...</td>
      <td>Toy Story (1995)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>[3, 5, 10]</td>
      <td>[48952, 58453, 20353, 5932, 7677, 16422, 23585...</td>
      <td>Jumanji (1995)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>[6, 16]</td>
      <td>[22590, 6651, 17688, 21398, 41566, 51540, 3803...</td>
      <td>Grumpier Old Men (1995)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>[6, 9, 16]</td>
      <td>[5956, 10772, 16687, 28762, 52968, 12059, 4824...</td>
      <td>Waiting to Exhale (1995)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>[6]</td>
      <td>[1785, 5229, 12797, 12978, 14653, 25202, 37295...</td>
      <td>Father of the Bride Part II (1995)</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>62418</th>
      <td>62419</td>
      <td>[9]</td>
      <td>[]</td>
      <td>We (2018)</td>
    </tr>
    <tr>
      <th>62419</th>
      <td>62420</td>
      <td>[8]</td>
      <td>[]</td>
      <td>Window of the Soul (2001)</td>
    </tr>
    <tr>
      <th>62420</th>
      <td>62421</td>
      <td>[6, 9]</td>
      <td>[]</td>
      <td>Bad Poems (2018)</td>
    </tr>
    <tr>
      <th>62421</th>
      <td>62422</td>
      <td>[1]</td>
      <td>[]</td>
      <td>A Girl Thing (2001)</td>
    </tr>
    <tr>
      <th>62422</th>
      <td>62423</td>
      <td>[2, 3, 9]</td>
      <td>[]</td>
      <td>Women of Devil's Island (1962)</td>
    </tr>
  </tbody>
</table>
<p>62423 rows × 4 columns</p>
</div>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">df_movie_joint_encoder.to_parquet(<span class="string">&quot;./df_movie_joint_encoder.pq&quot;</span>,index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<p>Given <code>ratings.csv</code>, we will sort user rating by timestamp in order to create time-order sequences.</p>
<p>Note that user ratings behaviors is tried to mimics user watch behaviors</p>
<h3><a href="#random-walk-methods" class="header-anchor"></a><span id="random-walk-methods">Random walk methods</span></h3><p>Convert rating into sequences by using random walk technique. We leverage source code from <a href="bperozzi@cs.stonybrook.edu">Bryan Perozzi</a></p>
<h4><a href="#implement-graph-class" class="header-anchor"></a><span id="implement-graph-class">Implement Graph class</span></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;Graph utilities.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> logging</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> io <span class="keyword">import</span> <span class="built_in">open</span></span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> six <span class="keyword">import</span> iterkeys</span><br><span class="line"><span class="keyword">from</span> six.moves <span class="keyword">import</span> <span class="built_in">range</span>, <span class="built_in">zip</span>, zip_longest</span><br><span class="line"></span><br><span class="line">logger = logging.getLogger(<span class="string">&quot;deepwalk&quot;</span>)</span><br><span class="line"></span><br><span class="line">LOGFORMAT = <span class="string">&quot;%(asctime).19s %(levelname)s %(filename)s: %(lineno)s %(message)s&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Graph</span>(<span class="params">defaultdict</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Efficient basic implementation of nx `Graph&#x27;  Undirected graphs with self loops&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Graph, self).__init__(<span class="built_in">list</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">nodes</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.keys()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">adjacency_iter</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.iteritems()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">random_walk</span>(<span class="params">self, path_length, alpha=<span class="number">0</span>, rand=random.Random(<span class="params"></span>), start=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot; Returns a truncated random walk.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">            path_length: Length of the random walk.</span></span><br><span class="line"><span class="string">            alpha: probability of restarts.</span></span><br><span class="line"><span class="string">            start: the start node of the random walk.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        G = self</span><br><span class="line">        <span class="keyword">if</span> start:</span><br><span class="line">            path = [start]</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># Sampling is uniform w.r.t V, and not w.r.t E</span></span><br><span class="line">            path = [rand.choice(<span class="built_in">list</span>(G.keys()))]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="built_in">len</span>(path) &lt; path_length:</span><br><span class="line">            cur = path[-<span class="number">1</span>]</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(G[cur]) &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">if</span> rand.random() &gt;= alpha:</span><br><span class="line">                    path.append(rand.choice(G[cur]))</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    path.append(path[<span class="number">0</span>])</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">return</span> [<span class="built_in">str</span>(node) <span class="keyword">for</span> node <span class="keyword">in</span> path]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_undirected</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        t0 = time()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">list</span>(self):</span><br><span class="line">            <span class="keyword">for</span> other <span class="keyword">in</span> self[v]:</span><br><span class="line">                <span class="keyword">if</span> v != other:</span><br><span class="line">                    self[other].append(v)</span><br><span class="line"></span><br><span class="line">        t1 = time()</span><br><span class="line">        logger.info(<span class="string">&#x27;make_directed: added missing edges &#123;&#125;s&#x27;</span>.<span class="built_in">format</span>(t1-t0))</span><br><span class="line"></span><br><span class="line">        self.make_consistent()</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_consistent</span>(<span class="params">self</span>):</span></span><br><span class="line">        t0 = time()</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> iterkeys(self):</span><br><span class="line">            self[k] = <span class="built_in">list</span>(<span class="built_in">sorted</span>(<span class="built_in">set</span>(self[k])))</span><br><span class="line"></span><br><span class="line">        t1 = time()</span><br><span class="line">        logger.info(<span class="string">&#x27;make_consistent: made consistent in &#123;&#125;s&#x27;</span>.<span class="built_in">format</span>(t1-t0))</span><br><span class="line"></span><br><span class="line">        self.remove_self_loops()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">remove_self_loops</span>(<span class="params">self</span>):</span></span><br><span class="line"></span><br><span class="line">        removed = <span class="number">0</span></span><br><span class="line">        t0 = time()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> self:</span><br><span class="line">            <span class="keyword">if</span> x <span class="keyword">in</span> self[x]:</span><br><span class="line">                self[x].remove(x)</span><br><span class="line">                removed += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        t1 = time()</span><br><span class="line"></span><br><span class="line">        logger.info(</span><br><span class="line">            <span class="string">&#x27;remove_self_loops: removed &#123;&#125; loops in &#123;&#125;s&#x27;</span>.<span class="built_in">format</span>(removed, (t1-t0)))</span><br><span class="line">        <span class="keyword">return</span> self</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_deepwalk_corpus_iter</span>(<span class="params">G, num_paths, path_length, alpha=<span class="number">0</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">                               rand=random.Random(<span class="params"><span class="number">0</span></span>)</span>):</span></span><br><span class="line"></span><br><span class="line">    nodes = <span class="built_in">list</span>(G.nodes())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> cnt <span class="keyword">in</span> <span class="built_in">range</span>(num_paths):</span><br><span class="line">        rand.shuffle(nodes)</span><br><span class="line">        <span class="keyword">for</span> node <span class="keyword">in</span> nodes:</span><br><span class="line">            <span class="keyword">yield</span> G.random_walk(path_length, rand=rand, alpha=alpha, start=node)</span><br><span class="line"></span><br><span class="line"><span class="comment"># http://stackoverflow.com/questions/312443/how-do-you-split-a-list-into-evenly-sized-chunks-in-python</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">grouper</span>(<span class="params">n, iterable, padvalue=<span class="literal">None</span></span>):</span></span><br><span class="line">    <span class="string">&quot;grouper(3, &#x27;abcdefg&#x27;, &#x27;x&#x27;) --&gt; (&#x27;a&#x27;,&#x27;b&#x27;,&#x27;c&#x27;), (&#x27;d&#x27;,&#x27;e&#x27;,&#x27;f&#x27;), (&#x27;g&#x27;,&#x27;x&#x27;,&#x27;x&#x27;)&quot;</span></span><br><span class="line">    <span class="keyword">return</span> zip_longest(*[<span class="built_in">iter</span>(iterable)]*n, fillvalue=padvalue)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_adjacencylist</span>(<span class="params">f</span>):</span></span><br><span class="line">    adjlist = []</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> f:</span><br><span class="line">        <span class="keyword">if</span> l <span class="keyword">and</span> l[<span class="number">0</span>] != <span class="string">&quot;#&quot;</span>:</span><br><span class="line">            introw = [<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> l.strip().split()]</span><br><span class="line">            row = [introw[<span class="number">0</span>]]</span><br><span class="line">            row.extend(<span class="built_in">set</span>(<span class="built_in">sorted</span>(introw[<span class="number">1</span>:])))</span><br><span class="line">            adjlist.extend([row])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> adjlist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_adjacencylist_unchecked</span>(<span class="params">f</span>):</span></span><br><span class="line">    adjlist = []</span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> f:</span><br><span class="line">        <span class="keyword">if</span> l <span class="keyword">and</span> l[<span class="number">0</span>] != <span class="string">&quot;#&quot;</span>:</span><br><span class="line">            adjlist.extend([[<span class="built_in">str</span>(x) <span class="keyword">for</span> x <span class="keyword">in</span> l.strip().split()]])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> adjlist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_adjacencylist</span>(<span class="params">file_, undirected=<span class="literal">False</span>, chunksize=<span class="number">10000</span>,</span>):</span></span><br><span class="line"></span><br><span class="line">    parse_func = parse_adjacencylist_unchecked</span><br><span class="line">    convert_func = from_adjlist_unchecked</span><br><span class="line"></span><br><span class="line">    adjlist = []</span><br><span class="line"></span><br><span class="line">    t0 = time()</span><br><span class="line"></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_) <span class="keyword">as</span> f:</span><br><span class="line">        <span class="keyword">for</span> idx, adj_chunk <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">map</span>(parse_func, grouper(<span class="built_in">int</span>(chunksize), f))):</span><br><span class="line">            adjlist.extend(adj_chunk)</span><br><span class="line">            total += <span class="built_in">len</span>(adj_chunk)</span><br><span class="line"></span><br><span class="line">    t1 = time()</span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">&#x27;Parsed &#123;&#125; edges with &#123;&#125; chunks in &#123;&#125;s&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        total, idx, t1-t0))</span><br><span class="line"></span><br><span class="line">    t0 = time()</span><br><span class="line">    G = convert_func(adjlist)</span><br><span class="line">    t1 = time()</span><br><span class="line"></span><br><span class="line">    logger.info(<span class="string">&#x27;Converted edges to graph in &#123;&#125;s&#x27;</span>.<span class="built_in">format</span>(t1-t0))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> undirected:</span><br><span class="line">        t0 = time()</span><br><span class="line">        G = G.make_undirected()</span><br><span class="line">        t1 = time()</span><br><span class="line">        logger.info(<span class="string">&#x27;Made graph undirected in &#123;&#125;s&#x27;</span>.<span class="built_in">format</span>(t1-t0))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> G</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">from_adjlist_unchecked</span>(<span class="params">adjlist</span>):</span></span><br><span class="line">    G = Graph()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> adjlist:</span><br><span class="line">        node = row[<span class="number">0</span>]</span><br><span class="line">        neighbors = row[<span class="number">1</span>:]</span><br><span class="line">        G[node] = neighbors</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> G</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4><a href="#generate-sequences" class="header-anchor"></a><span id="generate-sequences">Generate sequences</span></h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df_rating = pd.read_csv(<span class="string">&quot;ml-25m/ratings.csv&quot;</span>)</span><br><span class="line">df_rating[<span class="string">&quot;movieId&quot;</span>] =  movie_encoder.transform(df_rating[<span class="string">&quot;movieId&quot;</span>].tolist())</span><br><span class="line">df_rating_path = df_rating.groupby([<span class="string">&quot;userId&quot;</span>])[<span class="string">&quot;movieId&quot;</span>].agg(<span class="built_in">list</span>).reset_index()</span><br><span class="line"></span><br><span class="line"><span class="keyword">del</span> df_rating</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">random_seed = <span class="number">4111</span></span><br><span class="line">number_walks = <span class="number">10</span></span><br><span class="line">walk_length = <span class="number">20</span></span><br><span class="line">restart_prob = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line">min_len = <span class="number">3</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;paths_filtered.txt&quot;</span>,<span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f, tqdm(total=<span class="built_in">len</span>(df_rating_path)) <span class="keyword">as</span> pbar:    </span><br><span class="line">    <span class="keyword">for</span> _, row <span class="keyword">in</span> df_rating_path.iterrows():</span><br><span class="line">        all_paths = row[<span class="string">&quot;movieId&quot;</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Skip short sequences</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(all_paths) &lt; min_len:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        f.write(<span class="string">&quot; &quot;</span>.join([<span class="built_in">str</span>(node) <span class="keyword">for</span> node <span class="keyword">in</span> all_paths])+<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">    </span><br><span class="line">        pbar.update(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">G = load_adjacencylist(<span class="string">&quot;paths_filtered.txt&quot;</span>,undirected=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">cursor = build_deepwalk_corpus_iter(G,</span><br><span class="line">                                    num_paths=number_walks,</span><br><span class="line">                                    path_length=walk_length,</span><br><span class="line">                                    alpha=restart_prob,</span><br><span class="line">                                    rand=random.Random(random_seed))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;walks.txt&quot;</span>,<span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="keyword">for</span> path <span class="keyword">in</span> cursor:</span><br><span class="line">        f.write(<span class="string">&quot; &quot;</span>.join(path) + <span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>100%|██████████| 162541/162541 [00:09&lt;00:00, 16561.69it/s]
</code></pre>
<h2><a href="#deep-dive-into-model" class="header-anchor"></a><span id="deep-dive-into-model">Deep dive into model</span></h2><h3><a href="#generate-skip-gram-and-negative-sampling-for-picking-movies" class="header-anchor"></a><span id="generate-skip-gram-and-negative-sampling-for-picking-movies">Generate skip-gram and negative sampling for picking movies</span></h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">feature_schema = &#123;</span><br><span class="line">    <span class="string">&quot;genres&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;categorical_list&quot;</span>, <span class="comment"># there are categorical_list and categorical</span></span><br><span class="line">        <span class="string">&quot;size&quot;</span>: encoder_mapper[<span class="string">&quot;genres&quot;</span>].n_classes_,</span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="string">&quot;tag&quot;</span>: &#123;</span><br><span class="line">        <span class="string">&quot;type&quot;</span>: <span class="string">&quot;categorical_list&quot;</span>,</span><br><span class="line">        <span class="string">&quot;size&quot;</span>: encoder_mapper[<span class="string">&quot;tag&quot;</span>].n_classes_,        </span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_skipgram</span>(<span class="params">sentence, i, window_size,unk:<span class="built_in">int</span> = <span class="number">0</span></span>):</span></span><br><span class="line">    iword = sentence[i]</span><br><span class="line">    left = sentence[<span class="built_in">max</span>(i - window_size, <span class="number">0</span>): i]</span><br><span class="line">    right = sentence[i + <span class="number">1</span>: i + <span class="number">1</span> + window_size]</span><br><span class="line">    <span class="keyword">return</span> iword, [unk <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(window_size - <span class="built_in">len</span>(left))] + left + right + [unk <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(window_size - <span class="built_in">len</span>(right))]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MovieLenGraphPathDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        MovieLen Torch Dataset</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self, </span></span></span><br><span class="line"><span class="params"><span class="function">        file_path, </span></span></span><br><span class="line"><span class="params"><span class="function">        side_info_lookup: <span class="built_in">dict</span>=<span class="literal">None</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">        feature_schema:<span class="built_in">dict</span>=<span class="literal">None</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">        window_size: <span class="built_in">int</span>=<span class="number">5</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        subsample_rate: <span class="built_in">float</span> = <span class="number">0</span></span>) -&gt; <span class="literal">None</span>:</span></span><br><span class="line">    </span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">            file_path - string : Line text sequence file</span></span><br><span class="line"><span class="string">            side_info_lookup - dict: </span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.data = []</span><br><span class="line">        </span><br><span class="line">        self.wc = defaultdict(<span class="built_in">int</span>)        </span><br><span class="line">        self.window_size = window_size</span><br><span class="line">        self.side_info_lookup = side_info_lookup</span><br><span class="line">        self.feature_schema = feature_schema</span><br><span class="line">        </span><br><span class="line">        cols = <span class="built_in">list</span>(feature_schema.keys())</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(file_path) <span class="keyword">as</span> f:</span><br><span class="line">            step = <span class="number">0</span>            </span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                <span class="keyword">if</span> step % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;working on line: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(step),end=<span class="string">&quot;\r&quot;</span>)                </span><br><span class="line">                    </span><br><span class="line">                line = [<span class="built_in">int</span>(w.strip()) <span class="keyword">for</span> w <span class="keyword">in</span> line.strip().split() <span class="keyword">if</span> <span class="built_in">len</span>(w.strip()) &gt; <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(line)):</span><br><span class="line">                    self.wc[line[i]] += <span class="number">1</span></span><br><span class="line">                    </span><br><span class="line">                    center_word, neighbor_words = generate_skipgram(line, i, window_size)</span><br><span class="line">                    </span><br><span class="line">                    <span class="keyword">if</span> <span class="keyword">not</span> center_word <span class="keyword">in</span> self.side_info_lookup:</span><br><span class="line">                        <span class="keyword">continue</span></span><br><span class="line">                        </span><br><span class="line">                    <span class="keyword">for</span> neighbor_word <span class="keyword">in</span> neighbor_words:</span><br><span class="line">                        <span class="keyword">if</span> neighbor_word == <span class="number">0</span>:</span><br><span class="line">                            <span class="keyword">continue</span></span><br><span class="line">                            </span><br><span class="line">                        tmp = &#123;<span class="string">&quot;center_word&quot;</span>: center_word,<span class="string">&quot;neighbor_word&quot;</span>: neighbor_word,<span class="string">&quot;side_information&quot;</span>:&#123;&#125;&#125;</span><br><span class="line">                            </span><br><span class="line">                        <span class="keyword">for</span> col <span class="keyword">in</span> cols:</span><br><span class="line">                            <span class="keyword">if</span> col <span class="keyword">in</span> self.side_info_lookup[center_word]:</span><br><span class="line">                                tmp[<span class="string">&quot;side_information&quot;</span>][col] = self.side_info_lookup[center_word][col]</span><br><span class="line">                                </span><br><span class="line">                        self.data.append(tmp)</span><br><span class="line">            </span><br><span class="line">                step += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">        self.wc_arr = np.zeros(<span class="built_in">len</span>(side_info_lookup) + <span class="number">1</span>,dtype=<span class="built_in">int</span>)</span><br><span class="line">        <span class="keyword">for</span> k, v <span class="keyword">in</span> self.wc.items():</span><br><span class="line">            self.wc_arr[k] = v</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> subsample_rate &gt; <span class="number">0</span>:</span><br><span class="line">            wf = self.wc_arr / self.wc_arr.<span class="built_in">sum</span>()</span><br><span class="line">            ws = <span class="number">1</span> - np.sqrt(subsample_rate/wf)</span><br><span class="line">            ws = np.clip(ws, <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            data = []</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(self.data)):</span><br><span class="line">                <span class="keyword">if</span> random.random() &gt; ws[self.data[i][<span class="number">0</span>]]:</span><br><span class="line">                    data.append(self.data[i])</span><br><span class="line"></span><br><span class="line">            self.data = data            </span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.data[index]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data)</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_word_count</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> self.wc_arr</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">movie_ds = MovieLenGraphPathDataset(<span class="string">&quot;walks.txt&quot;</span>,</span><br><span class="line">                                    side_info_lookup=movie_metadata_info,</span><br><span class="line">                                    feature_schema=feature_schema,</span><br><span class="line">                                    window_size=<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<pre><code>working on line: 88000
</code></pre>
<p>Wrap-up with Torch DataLoader</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">padding_tensor</span>(<span class="params">arr,maxlen, dtype</span>):</span></span><br><span class="line">    padded_sess = torch.zeros(<span class="built_in">len</span>(arr), maxlen, dtype=dtype)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(arr)):</span><br><span class="line">        padded_sess[i, :<span class="built_in">len</span>(arr[i])] = arr[i]</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> padded_sess</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_dataloader</span>(<span class="params">dataset, feature_mapper,batch_size=<span class="number">64</span>,shuffle=<span class="literal">True</span>,num_workers=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line">                </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">collate_fn</span>(<span class="params">inputs</span>):</span></span><br><span class="line">        outputs = &#123;k: [] <span class="keyword">for</span> k <span class="keyword">in</span> feature_mapper.keys()&#125;</span><br><span class="line">        outputs[<span class="string">&quot;center_word&quot;</span>] = []</span><br><span class="line">        outputs[<span class="string">&quot;neighbor_word&quot;</span>] = []   </span><br><span class="line">        </span><br><span class="line">        max_len_mapper = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(inputs)):</span><br><span class="line">            outputs[<span class="string">&quot;center_word&quot;</span>].append(torch.tensor(inputs[i][<span class="string">&quot;center_word&quot;</span>], dtype=torch.<span class="built_in">int</span>))</span><br><span class="line">            outputs[<span class="string">&quot;neighbor_word&quot;</span>].append(torch.tensor(inputs[i][<span class="string">&quot;neighbor_word&quot;</span>], dtype=torch.<span class="built_in">int</span>))</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> feature_mapper.keys():</span><br><span class="line">                outputs[k].append(torch.tensor(inputs[i][<span class="string">&quot;side_information&quot;</span>][k],dtype=torch.<span class="built_in">int</span>))</span><br><span class="line">                max_len_mapper[k] = <span class="built_in">max</span>(<span class="built_in">len</span>(inputs[i][<span class="string">&quot;side_information&quot;</span>][k]),max_len_mapper[k])</span><br><span class="line">        </span><br><span class="line">        outputs[<span class="string">&quot;center_word&quot;</span>] = torch.tensor(outputs[<span class="string">&quot;center_word&quot;</span>], dtype=torch.<span class="built_in">int</span>)</span><br><span class="line">        outputs[<span class="string">&quot;neighbor_word&quot;</span>] = torch.tensor(outputs[<span class="string">&quot;neighbor_word&quot;</span>], dtype=torch.<span class="built_in">int</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> feature_mapper.keys():            </span><br><span class="line">            <span class="keyword">if</span> feature_mapper[k][<span class="string">&quot;type&quot;</span>] == <span class="string">&quot;categorical&quot;</span>:</span><br><span class="line">                outputs[k] = torch.tensor(outputs[k], dtype=torch.<span class="built_in">int</span>)</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">elif</span> feature_mapper[k][<span class="string">&quot;type&quot;</span>] == <span class="string">&quot;categorical_list&quot;</span>:</span><br><span class="line">                outputs[k] = padding_tensor(outputs[k],max_len_mapper[k],dtype=torch.<span class="built_in">int</span>)      </span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> outputs</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> DataLoader(dataset, batch_size = batch_size, shuffle = shuffle, collate_fn = collate_fn, num_workers=num_workers)</span><br></pre></td></tr></table></figure>

<h3><a href="#weighted-skip-gram" class="header-anchor"></a><span id="weighted-skip-gram">Weighted Skip Gram</span></h3><p>Let’s start of by defining the problem. For the sake of charity , we use $W$ to define the embedding matrix of items or Side Information (SI). Specifically, $W_{v}^{0}$ denote the embedding of item $v$, and $W_{v}^{i}$ denote s-th type of embedding of the s-th type SI attached to item $v$</p>
<p>Then, for item $v$ with $n$ SIs, we have $n$ + 1 vector $W_{v}^{0}$ ,$W_{v}^{1}$,…$W_{v}^{n}$ $\in$ $R^{d}$ with d is embedding dim. We proposed weighted layer to aggregate embedding of SI related to items. Given $a^j_v$ is weight of the s-type of SI of side information of item v with $a_0^v$ denoting the weight of item v itself. The formula is defined below the following:</p>
<p>\begin{align*}<br>H_{v} = \frac{\sum_{j = 0}^{n} e^{a^j_v}* W_v^j }{\sum_{j = 0}^{n} e^{a^j_v} } \<br>\end{align*}</p>
<p>where we calculate $e^{a^j_v}$ to ensure contribution of each SI is positive, ${\sum_{j = 0}^{n} e^{a^j_v} }$ is normalized of weights of each SI embedding.</p>
<p>For node $v$ and its context nodes $u$ in the training data, we represent $Z_u \in R_d$ to represent its embedding and $y$ is label. The objective function is defined below:</p>
<p>\begin{align*}<br>L(u,v, y) =  - ( ylog(\sigma(H_v^TZ_u)) +  (1-y)(log(1-\sigma(H_v^TZ_u)))) \<br>\end{align*}</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> <span class="type">List</span>, <span class="type">Union</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.utils.data</span><br><span class="line"><span class="keyword">import</span> pytorch_lightning <span class="keyword">as</span> pl</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fixed_unigram_candidate_sampler</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">    true_classes: <span class="type">Union</span>[np.array, torch.Tensor],</span></span></span><br><span class="line"><span class="params"><span class="function">    num_true: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    num_samples: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    range_max: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">    unigrams: <span class="type">List</span>[<span class="type">Union</span>[<span class="built_in">int</span>, <span class="built_in">float</span>]],</span></span></span><br><span class="line"><span class="params"><span class="function">    unique: <span class="built_in">bool</span> = <span class="literal">False</span>,    </span></span></span><br><span class="line"><span class="params"><span class="function">    distortion: <span class="built_in">float</span> = <span class="number">1.</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Generate candidates based on positive examples. I convert from tensorflow code to python code</span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        true_classes:  A Tensor of type int64 and shape [batch_size,num_true]. The target classes.</span></span><br><span class="line"><span class="string">        num_true: An int. The number of target classes per training example.</span></span><br><span class="line"><span class="string">        num_samples: An int. The number of classes to randomly sample.</span></span><br><span class="line"><span class="string">        range_max: An int. The number of possible classes.</span></span><br><span class="line"><span class="string">        unigrams: A list of unigram counts or probabilities, one per ID in sequential order. Exactly one of vocab_file and unigrams should be passed to this operation.</span></span><br><span class="line"><span class="string">        unique: A bool. Determines whether all sampled classes in a batch are unique.</span></span><br><span class="line"><span class="string">        distortion: distortion is used to skew the unigram probability distribution. Each weight is first raised to the distortion&#x27;s power before adding to the internal unigram distribution. As a result, distortion = 1.0 gives regular unigram sampling (as defined by the vocab file), and distortion = 0.0 gives a uniform distribution.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(true_classes, torch.Tensor):</span><br><span class="line">        true_classes = true_classes.detach().cpu().numpy()</span><br><span class="line"></span><br><span class="line">    unigrams = np.array(unigrams)</span><br><span class="line">    <span class="keyword">if</span> distortion != <span class="number">1.</span>:</span><br><span class="line">        unigrams = unigrams.astype(np.float64) ** distortion</span><br><span class="line"></span><br><span class="line">    result = []</span><br><span class="line">    has_seen = <span class="built_in">set</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(true_classes)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(true_classes[i])):</span><br><span class="line">            has_seen.add(true_classes[i][j])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> range_max &lt; num_samples <span class="keyword">and</span> unique:</span><br><span class="line">        <span class="keyword">raise</span> Exception(<span class="string">&quot;Range max is lower than num samples&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(result) &lt; num_samples:</span><br><span class="line">        sampler = torch.utils.data.WeightedRandomSampler(unigrams, num_samples,)</span><br><span class="line">        candidates = np.array(<span class="built_in">list</span>(sampler))</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> candidates:</span><br><span class="line">            <span class="keyword">if</span> unique:</span><br><span class="line">                <span class="keyword">if</span> item <span class="keyword">not</span> <span class="keyword">in</span> has_seen:</span><br><span class="line">                    result.append(item)</span><br><span class="line">                    has_seen.add(item)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                result.append(item)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SkigGram</span>(<span class="params">pl.LightningModule</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        self, </span></span></span><br><span class="line"><span class="params"><span class="function">        embedding_size: <span class="built_in">int</span>, </span></span></span><br><span class="line"><span class="params"><span class="function">        embedding_dim: <span class="built_in">int</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        side_information_schema: <span class="built_in">dict</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        word_count_table: np.ndarray,</span></span></span><br><span class="line"><span class="params"><span class="function">        lr: <span class="built_in">float</span> = <span class="number">0.001</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        negative: <span class="built_in">int</span> = <span class="number">5</span>,</span></span></span><br><span class="line"><span class="params"><span class="function">        </span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            embedding_size: An int, unique word number</span></span><br><span class="line"><span class="string">            embedding_dim: An int, embedding dimension</span></span><br><span class="line"><span class="string">            side_information_schema: A dict, side information schema contains name, type of side information</span></span><br><span class="line"><span class="string">            word_count_table: A array, define word count of item in order to generate negative sampling</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span>  </span><br><span class="line">        <span class="built_in">super</span>(SkigGram, self).__init__()</span><br><span class="line">        self.side_information_schema = side_information_schema</span><br><span class="line">        self.embedding_size = embedding_size</span><br><span class="line"></span><br><span class="line">        self.embedding_dim = embedding_dim</span><br><span class="line">        self.negative = negative</span><br><span class="line">        self.wc = word_count_table</span><br><span class="line">        self.lr = lr</span><br><span class="line"></span><br><span class="line">        <span class="comment"># center word embedding</span></span><br><span class="line">        self.center_word_embed = nn.Embedding(embedding_size, embedding_dim,padding_idx=<span class="number">0</span>)</span><br><span class="line">        <span class="comment"># neighbor word embedding</span></span><br><span class="line">        self.neighbor_word_embed = nn.Embedding(embedding_size, embedding_dim,padding_idx=<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        self.si_dict = nn.ModuleDict()</span><br><span class="line"></span><br><span class="line">        <span class="comment"># side information embedding</span></span><br><span class="line">        self.si_keys = []</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> key, info <span class="keyword">in</span> side_information_schema.items():</span><br><span class="line">            self.si_keys.append(key)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> info[<span class="string">&quot;type&quot;</span>] == <span class="string">&quot;categorical&quot;</span>:</span><br><span class="line">                self.si_dict[key] = nn.Embedding(info[<span class="string">&quot;size&quot;</span>],embedding_dim,padding_idx=<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">elif</span> info[<span class="string">&quot;type&quot;</span>] == <span class="string">&quot;categorical_list&quot;</span>:</span><br><span class="line">                self.si_dict[key] = nn.EmbeddingBag(info[<span class="string">&quot;size&quot;</span>],embedding_dim,padding_idx=<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        self._weight_init()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">_weight_init</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            self.center_word_embed.weight.data.normal_(<span class="number">0.</span>, <span class="number">0.01</span>)</span><br><span class="line">            self.neighbor_word_embed.weight.data.normal_(<span class="number">0.</span>, <span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">for</span> key <span class="keyword">in</span> self.si_dict.keys():</span><br><span class="line">                self.si_dict[key].weight.data.normal_(<span class="number">0.</span>, <span class="number">0.01</span>)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># init side information weight </span></span><br><span class="line">        self.register_buffer(<span class="string">&quot;embedding_weight&quot;</span>,torch.rand((<span class="built_in">len</span>(self.si_keys) + <span class="number">1</span>, <span class="number">1</span>), requires_grad=<span class="literal">True</span>,))</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_vector</span>(<span class="params">self, data:<span class="built_in">dict</span></span>):</span></span><br><span class="line">        embed_center_word = self.center_word_embed(data[<span class="string">&quot;center_word&quot;</span>].to(self.device)) <span class="comment"># batch_size * embed_dim</span></span><br><span class="line"></span><br><span class="line">        information_list = [embed_center_word]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># side information</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> self.si_keys:</span><br><span class="line">            information_list.append(self.si_dict[k](data[k].to(self.device)))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># word and side information embeding list</span></span><br><span class="line">        information_embed = torch.cat(information_list, dim=<span class="number">0</span>).view(<span class="built_in">len</span>(information_list), -<span class="number">1</span>, self.embedding_dim)</span><br><span class="line">        </span><br><span class="line">        exp_embedding_weights = torch.exp(self.embedding_weight.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        weight_sum_pooling = information_embed * exp_embedding_weights / torch.<span class="built_in">sum</span>(exp_embedding_weights)</span><br><span class="line">        </span><br><span class="line">        embed_center_word_side_information = torch.<span class="built_in">sum</span>(weight_sum_pooling, dim=<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> embed_center_word_side_information</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, data: <span class="built_in">dict</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Argument</span></span><br><span class="line"><span class="string">            data: dictionary of torch tensor</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># assert &quot;center_word&quot; in data</span></span><br><span class="line"></span><br><span class="line">        embed_center_word = self.center_word_embed(data[<span class="string">&quot;center_word&quot;</span>].to(self.device)) <span class="comment"># batch_size * embed_dim</span></span><br><span class="line"></span><br><span class="line">        information_list = [embed_center_word]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># neighbor word</span></span><br><span class="line">        embed_neighbor_word = self.neighbor_word_embed(data[<span class="string">&quot;neighbor_word&quot;</span>].to(self.device)) <span class="comment"># batch_size * 1 * embed_dim</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># neg word</span></span><br><span class="line">        neg_word = torch.tensor(fixed_unigram_candidate_sampler(</span><br><span class="line">            data[<span class="string">&quot;center_word&quot;</span>].unsqueeze(<span class="number">1</span>),</span><br><span class="line">            num_true=<span class="number">1</span>,</span><br><span class="line">            num_samples=<span class="built_in">len</span>(data[<span class="string">&quot;center_word&quot;</span>]) * self.negative,</span><br><span class="line">            range_max=<span class="built_in">len</span>(self.wc),</span><br><span class="line">            unigrams=self.wc,</span><br><span class="line">        ),dtype=torch.<span class="built_in">int</span>).reshape((-<span class="number">1</span>,self.negative))</span><br><span class="line">        </span><br><span class="line">        embed_neg_word = self.neighbor_word_embed(neg_word.to(self.device)) <span class="comment"># batch_size * K * embed_dim       </span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># side information</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> self.si_keys:</span><br><span class="line">            information_list.append(self.si_dict[k](data[k].to(self.device)))</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="comment"># word and side information embeding list</span></span><br><span class="line">        information_embed = torch.cat(information_list, dim=<span class="number">0</span>).view(<span class="built_in">len</span>(information_list), -<span class="number">1</span>, self.embedding_dim)</span><br><span class="line">        </span><br><span class="line">        exp_embedding_weights = torch.exp(self.embedding_weight.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">        </span><br><span class="line">        weight_sum_pooling = information_embed * exp_embedding_weights / torch.<span class="built_in">sum</span>(exp_embedding_weights)</span><br><span class="line">        </span><br><span class="line">        embed_center_word_side_information = torch.<span class="built_in">sum</span>(weight_sum_pooling, dim=<span class="number">0</span>)        </span><br><span class="line"></span><br><span class="line">        score = torch.<span class="built_in">sum</span>(torch.mul(embed_center_word_side_information, embed_neighbor_word.squeeze()), dim=<span class="number">1</span>)</span><br><span class="line">        score = torch.clamp(score, <span class="built_in">max</span>=<span class="number">10</span>, <span class="built_in">min</span>=-<span class="number">10</span>)</span><br><span class="line">        score = -F.logsigmoid(score)</span><br><span class="line"></span><br><span class="line">        neg_score = torch.bmm(embed_neg_word, embed_center_word_side_information.unsqueeze(<span class="number">2</span>)).squeeze()</span><br><span class="line">        neg_score = torch.clamp(neg_score, <span class="built_in">max</span>=<span class="number">10</span>, <span class="built_in">min</span>=-<span class="number">10</span>)</span><br><span class="line">        neg_score = -torch.<span class="built_in">sum</span>(F.logsigmoid(-neg_score), dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> torch.mean(score + neg_score)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_embedding</span>(<span class="params">self, id2word, file_name</span>):</span></span><br><span class="line">        embedding = self.u_embeddings.weight.cpu().data.numpy()</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(file_name, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            f.write(<span class="string">&#x27;%d %d\n&#x27;</span> % (<span class="built_in">len</span>(id2word), self.emb_dimension))</span><br><span class="line">            <span class="keyword">for</span> wid, w <span class="keyword">in</span> id2word.items():</span><br><span class="line">                e = <span class="string">&#x27; &#x27;</span>.join(<span class="built_in">map</span>(<span class="keyword">lambda</span> x: <span class="built_in">str</span>(x), embedding[wid]))</span><br><span class="line">                f.write(<span class="string">&#x27;%s %s\n&#x27;</span> % (w, e))</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">configure_optimizers</span>(<span class="params">self</span>):</span></span><br><span class="line">        optimizer = torch.optim.Adam(self.parameters(),lr=self.lr)</span><br><span class="line">        <span class="keyword">return</span> optimizer</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">training_step</span>(<span class="params">self, train_batch, batch_idx</span>):</span></span><br><span class="line">        x = train_batch</span><br><span class="line">        loss = model(x).mean()</span><br><span class="line">        </span><br><span class="line">        self.log(<span class="string">&#x27;train_loss&#x27;</span>, loss)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> loss    </span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">write_histograms</span>(<span class="params">self,</span>):</span></span><br><span class="line">        <span class="comment"># iterating through all parameters</span></span><br><span class="line">        <span class="keyword">for</span> name,params <span class="keyword">in</span> self.named_parameters():          </span><br><span class="line">            self.logger.experiment.add_histogram(name,params,self.current_epoch)</span><br><span class="line">            </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">training_epoch_end</span>(<span class="params">self,outputs</span>):</span></span><br><span class="line">        self.write_histograms()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>().training_epoch_end(outputs)</span><br><span class="line">    </span><br></pre></td></tr></table></figure>

<h3><a href="#algorithm-training" class="header-anchor"></a><span id="algorithm-training">Algorithm Training</span></h3><p>We use Pytorch lightning Trainer to speed up multi-gpus and multi-processing Data Loader</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> pytorch_lightning <span class="keyword">import</span> loggers <span class="keyword">as</span> pl_loggers</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">num_gpus = torch.cuda.device_count()</span><br><span class="line"></span><br><span class="line">lr = <span class="number">0.001</span></span><br><span class="line">epochs = <span class="number">5</span></span><br><span class="line">negative_items = <span class="number">5</span></span><br><span class="line">batch_size = <span class="number">256</span> * num_gpus</span><br><span class="line">num_items = <span class="built_in">len</span>(movie_metadata_info) + <span class="number">3</span></span><br><span class="line">embedding_dim = <span class="number">50</span></span><br><span class="line"></span><br><span class="line">data_loader = get_dataloader(</span><br><span class="line">    movie_ds,</span><br><span class="line">    feature_schema,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">    num_workers=num_gpus)</span><br><span class="line"></span><br><span class="line">model = SkigGram(</span><br><span class="line">    num_items,</span><br><span class="line">    embedding_dim,</span><br><span class="line">    feature_schema,</span><br><span class="line">    movie_ds.get_word_count(),</span><br><span class="line">    lr=lr,</span><br><span class="line">    negative=negative_items,)</span><br><span class="line"></span><br><span class="line">tb_logger = pl_loggers.TensorBoardLogger(<span class="string">&quot;logs/&quot;</span>,)</span><br><span class="line">trainer = pl.Trainer(</span><br><span class="line">    gpus=num_gpus, </span><br><span class="line">    strategy=<span class="string">&quot;dp&quot;</span>,</span><br><span class="line">    max_epochs=epochs,</span><br><span class="line">    accelerator=<span class="string">&quot;gpu&quot;</span>, </span><br><span class="line">    log_every_n_steps=<span class="number">1000</span>,</span><br><span class="line">    flush_logs_every_n_steps=<span class="number">1000</span>,</span><br><span class="line">    logger=tb_logger)</span><br></pre></td></tr></table></figure>

<pre><code>GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
/home/jovyan/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:59: LightningDeprecationWarning: Setting `Trainer(flush_logs_every_n_steps=1000)` is deprecated in v1.5 and will be removed in v1.7. Please configure flushing in the logger instead.
  rank_zero_deprecation(
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainer.fit(model, data_loader,)</span><br></pre></td></tr></table></figure>

<pre><code>LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]

  | Name                | Type       | Params
---------------------------------------------------
0 | center_word_embed   | Embedding  | 3.1 M 
1 | neighbor_word_embed | Embedding  | 3.1 M 
2 | si_dict             | ModuleDict | 3.3 M 
---------------------------------------------------
9.5 M     Trainable params
0         Non-trainable params
9.5 M     Total params
38.055    Total estimated model params size (MB)
/home/jovyan/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(



Training: 0it [00:00, ?it/s]
</code></pre>
<p>We just uploaded Tensorboard into TensorHub. Check it out on this <a target="_blank" rel="noopener" href="https://tensorboard.dev/experiment/u9DjL7uWQdqQnQxKJZ6iVA/#scalars">link</a></p>
<h2><a href="#testing-model" class="header-anchor"></a><span id="testing-model">Testing model </span></h2><p>First, we take our movie embedding from model</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> gensim.models <span class="keyword">import</span> KeyedVectors</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convert_to_tensor</span>(<span class="params">entity_id,data</span>):</span></span><br><span class="line">    tmp = &#123;<span class="string">&quot;center_word&quot;</span>: torch.tensor([entity_id],dtype=torch.<span class="built_in">int</span>)&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> k, v <span class="keyword">in</span> data.items():</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(v) == <span class="number">0</span>:</span><br><span class="line">            v = [<span class="number">0</span>]</span><br><span class="line">        tmp[k] = torch.tensor([v],dtype=torch.<span class="built_in">int</span>)</span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> tmp</span><br><span class="line"></span><br><span class="line">X = np.zeros((<span class="built_in">len</span>(movie_metadata_info) + <span class="number">3</span>,embedding_dim))</span><br><span class="line"><span class="keyword">for</span> entity_id, entity_info <span class="keyword">in</span> tqdm(movie_metadata_info.items()):</span><br><span class="line">    X[entity_id] = model.compute_vector(convert_to_tensor(entity_id,entity_info)).detach().cpu().numpy()    </span><br><span class="line"></span><br><span class="line">kv_metadata = KeyedVectors(vector_size=embedding_dim, count=<span class="built_in">len</span>(X))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(X)-<span class="number">1</span>):</span><br><span class="line">    kv_metadata.add_vector(i, X[i])</span><br></pre></td></tr></table></figure>

<pre><code>100%|██████████| 62423/62423 [00:13&lt;00:00, 4691.08it/s]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorboard <span class="keyword">as</span> tb</span><br><span class="line">tf.io.gfile = tb.compat.tensorflow_stub.io.gfile</span><br><span class="line"></span><br><span class="line">labels = df_movie_joint_encoder[<span class="string">&quot;title&quot;</span>].tolist()</span><br><span class="line">tb_logger.experiment.add_embedding(X[:<span class="built_in">len</span>(labels)],labels)</span><br></pre></td></tr></table></figure>

<pre><code>warning: Embedding dir exists, did you set global_step for add_embedding()?
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"></span><br></pre></td></tr></table></figure>

<p>Imagine that we just uploaded Spiderman Far Frome Home, new movie on Dec 2021 into our system.</p>
<p>The movie is new for us so we want to find similar movies related to Spiderman FFH. The movie is no interaction before, our team will assign genres and tags for this movie</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">response = <span class="string">&quot;&quot;&quot;&#123;&quot;status&quot;:&quot;success&quot;,&quot;data&quot;:&#123;&quot;movieId&quot;:263007,&quot;totalTagNum&quot;:112,&quot;scoredTags&quot;:[&#123;&quot;tag&quot;:&quot;Marvel Cinematic Universe&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:21,&quot;positive&quot;:15,&quot;neutral&quot;:3,&quot;negative&quot;:3,&quot;score&quot;:21.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Marvel&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:18,&quot;positive&quot;:12,&quot;neutral&quot;:4,&quot;negative&quot;:2,&quot;score&quot;:18.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;multiverse&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:15,&quot;positive&quot;:12,&quot;neutral&quot;:3,&quot;negative&quot;:0,&quot;score&quot;:15.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;spider-man&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:12,&quot;positive&quot;:11,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:12.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;I&#x27;m something of a scientist myself&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:10,&quot;positive&quot;:9,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:10.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Fan service&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:9,&quot;positive&quot;:6,&quot;neutral&quot;:3,&quot;negative&quot;:0,&quot;score&quot;:9.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;great cgi&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:9,&quot;positive&quot;:9,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:9.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;tom holland&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:6,&quot;positive&quot;:3,&quot;neutral&quot;:3,&quot;negative&quot;:0,&quot;score&quot;:6.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Andrew Garfield&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:5,&quot;positive&quot;:5,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:5.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;New York City&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:5,&quot;positive&quot;:4,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:5.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Tobey Maguire&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:5,&quot;positive&quot;:5,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:5.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Willem Dafoe&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:5,&quot;positive&quot;:5,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:5.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;actor reprises previous role&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:5,&quot;positive&quot;:4,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:5.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;crossover&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:5,&quot;positive&quot;:4,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:5.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;magic&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:5,&quot;positive&quot;:4,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:5.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;nostalgia&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:5,&quot;positive&quot;:4,&quot;neutral&quot;:0,&quot;negative&quot;:1,&quot;score&quot;:5.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;sorcerer&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:5,&quot;positive&quot;:4,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:5.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;casting a spell&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:4,&quot;positive&quot;:3,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:4.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Alfred Molina&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:3,&quot;positive&quot;:3,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:3.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;lawyer&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:3,&quot;positive&quot;:1,&quot;neutral&quot;:1,&quot;negative&quot;:1,&quot;score&quot;:2.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;sandman the marvel comics character&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:3,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:2,&quot;score&quot;:3.0,&quot;dominantAffect&quot;:&quot;negative&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;statue of liberty&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:3,&quot;positive&quot;:2,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:3.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;green goblin character&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:2,&quot;positive&quot;:1,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:2.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;trippy&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:2,&quot;positive&quot;:1,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;unmasked&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:2,&quot;positive&quot;:1,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:2.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot; Nostalgia Done Right&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:1,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;2020s&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Beautifully completes Tom Holland&#x27;s evolution from a boy reliant on the avengers and Tony to a man with his own suit, his own problems and his own responsibility, because after all with great power comes great responsibility&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:0.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Doctor Strange&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:1,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Dr. Strange&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Greatest marvel film ever&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:0.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Statue of Liberty&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:1,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;Zendaya&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;a list&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;action&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:1,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;american patriotism&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:0,&quot;negative&quot;:1,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;negative&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;based on comic&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;based on comic book&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;bechdel test: fail&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:0,&quot;negative&quot;:1,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;negative&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;best friend&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;best hits&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;biopunk&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;bomb&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:0.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;bridge&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;british actor playing american character&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;cameos&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;car&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;cinematography&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:1,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;comic book&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;construction site&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;costume&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;costumed hero&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;doctor octopus character&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;doctor strange character&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;dr. curt connors character&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;electricity&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;electro character&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;exciting&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:1,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;falling from height&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;fight&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;final showdown&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;fixes Spider-Man&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;framed for murder&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;friend&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;funny&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;good characters&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:1,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;greatest hits&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;hero&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;high school&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;identity revealed&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;j. jonah jameson character&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;lightning&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;lizard character&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;love interest&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;many characters&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;many villains&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;marvel cinematic universe (mcu)&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;marvel comics&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;marvel entertainment&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;mistaken identity&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;multiple villains&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;night&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;nostalgic&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:1,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;overrated&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:0,&quot;negative&quot;:1,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;negative&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;peter parker character&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;plot holes&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:0,&quot;negative&quot;:1,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;negative&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;power&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;protest&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;psychotronic film&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;rogues gallery&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;sand&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;scaffolding&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;scientist&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;sequel&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;shared universe&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;slimehouse&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;spell gone awry&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;spider man character&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;superhero&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;surrealism&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;swing&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;teenage boy&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;teenage girl&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;teenage superhero&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;teenager&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;third part&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;thrilling&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;train&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;trio&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;villain&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;villain team up&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:0,&quot;neutral&quot;:1,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;neutral&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;,&#123;&quot;tag&quot;:&quot;writing&quot;,&quot;tagCountsViewModel&quot;:&#123;&quot;total&quot;:1,&quot;positive&quot;:1,&quot;neutral&quot;:0,&quot;negative&quot;:0,&quot;score&quot;:1.0,&quot;dominantAffect&quot;:&quot;positive&quot;&#125;,&quot;userHasTagged&quot;:false,&quot;userAffect&quot;:null,&quot;userRating&quot;:null&#125;]&#125;&#125;&quot;&quot;&quot;</span></span><br><span class="line">tags_response = json.loads(response)</span><br><span class="line">tags = [item[<span class="string">&quot;tag&quot;</span>].strip().lower() <span class="keyword">for</span> item <span class="keyword">in</span> tags_response[<span class="string">&quot;data&quot;</span>][<span class="string">&quot;scoredTags&quot;</span>] <span class="keyword">if</span> item[<span class="string">&quot;tagCountsViewModel&quot;</span>].get(<span class="string">&quot;dominantAffect&quot;</span>,<span class="string">&quot;&quot;</span>) == <span class="string">&quot;positive&quot;</span>]</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">test_movie_info = &#123;</span><br><span class="line">    <span class="string">&quot;genres&quot;</span>: [<span class="string">&quot;action&quot;</span>, <span class="string">&quot;adventure&quot;</span>, <span class="string">&quot;science fiction&quot;</span>],</span><br><span class="line">    <span class="string">&quot;tag&quot;</span>: tags</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">test_movie_tags = &#123;k: encoder_mapper[k].transform(v) <span class="keyword">for</span> k, v <span class="keyword">in</span> test_movie_info.items()&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">X_query = model.compute_vector(convert_to_tensor(<span class="number">0</span>,test_movie_tags,)).detach().cpu().numpy()</span><br><span class="line">list_candidates_ids = &#123;movie_id: score <span class="keyword">for</span> movie_id, score <span class="keyword">in</span> kv_metadata.similar_by_vector(X_query[<span class="number">0</span>])&#125;</span><br><span class="line">df_movie_joint_encoder[df_movie_joint_encoder[<span class="string">&quot;movieId&quot;</span>].isin(list_candidates_ids)]\</span><br><span class="line">    .assign(score=<span class="keyword">lambda</span> x: x[<span class="string">&quot;movieId&quot;</span>].<span class="built_in">map</span>(<span class="keyword">lambda</span> d: list_candidates_ids[d]))\</span><br><span class="line">    .sort_values(by=[<span class="string">&quot;score&quot;</span>],ascending=<span class="literal">False</span>)[[<span class="string">&quot;title&quot;</span>,<span class="string">&quot;score&quot;</span>]]</span><br></pre></td></tr></table></figure>

<pre><code>/home/jovyan/miniconda3/lib/python3.8/site-packages/gensim/models/keyedvectors.py:772: RuntimeWarning: invalid value encountered in true_divide
  dists = dot(self.vectors[clip_start:clip_end], mean) / self.norms[clip_start:clip_end]
</code></pre>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;
</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>title</th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>43355</th>
      <td>Marvel One-Shot: All Hail the King (2014)</td>
      <td>0.763174</td>
    </tr>
    <tr>
      <th>59441</th>
      <td>Batman: Hush (2019)</td>
      <td>0.732942</td>
    </tr>
    <tr>
      <th>7098</th>
      <td>D.O.A. (1950)</td>
      <td>0.725314</td>
    </tr>
    <tr>
      <th>44344</th>
      <td>Marvel One-Shot: Agent Carter (2013)</td>
      <td>0.722448</td>
    </tr>
    <tr>
      <th>43369</th>
      <td>Marvel One-Shot: The Consultant (2011)</td>
      <td>0.719176</td>
    </tr>
    <tr>
      <th>50639</th>
      <td>Rendel (2017)</td>
      <td>0.713440</td>
    </tr>
    <tr>
      <th>27213</th>
      <td>45 Years (2015)</td>
      <td>0.709849</td>
    </tr>
    <tr>
      <th>44351</th>
      <td>Marvel One-Shot: A Funny Thing Happened on the...</td>
      <td>0.695612</td>
    </tr>
    <tr>
      <th>40174</th>
      <td>The BFG (2016)</td>
      <td>0.694954</td>
    </tr>
    <tr>
      <th>41081</th>
      <td>The Three Musketeers (1946)</td>
      <td>0.689934</td>
    </tr>
  </tbody>
</table>
</div>

<p>Model is learned quite well about similar movies related to Spider-man FFH movie. In general, we can see lots of super-heroes movies on top movies. We have Marvel Cinematic Universe movies, DC movies and sci-fi movies as well</p>
<h1><a href="#end-note" class="header-anchor"></a><span id="end-note">End Note </span></h1><p>We have implemented Graph Embedding with Side Information to incorporate item side information. We introduced how to construct items graph from user’s behavior history, and learn the embeddings of all items in the graph. The item embeddings are employed to compute pairwise similarities between all items, which are then used in the recommendation process. To alleviate the sparsity and cold start problems, side information is incorporated into the graph embedding framework.</p>
<p>In scope of data, we just added two metadata genres and user tags into our model. In future, we can add new features such as actors, actress, directors,…</p>
<p>The model in this notebook is just based on negative sampling. We can think to integrate with more advanced graph embedding like Graph Convolutional Network, Knowledge Graph.</p>
<p>Stay tuned!</p>
<h1><a href="#reference" class="header-anchor"></a><span id="reference">Reference </span></h1><p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1803.02349.pdf">Billion-scale Commodity Embedding for E-commerce Recommendation in Alibaba</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/busesese/Word2Vec-with-side-information">Word2vec</a></p>


                <hr>

                <ul class="pager">
                    
                        <li class="previous">
                            <a href="/ml-test-score-part-one/" data-toggle="tooltip" data-placement="top" title="What is your ML Test Score?">&larr; Previous Post</a>
                        </li>
                    
                    
                </ul>

            </div>
    <!-- Side Catalog Container -->
        

    <!-- Sidebar Container -->

            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                

                <!-- Friends Blog -->
                
            </div>

        </div>
    </div>
</article>





    <!-- Footer -->
    <!-- Footer -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">
                
                
                

                

                

                
                    <li>
                        <a target="_blank"  href="https://github.com/NhuanTDBK">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                
                    <li>
                        <a target="_blank"  href="https://www.linkedin.com/in/nhuantranduc">
                            <span class="fa-stack fa-lg">
                                <i class="fa fa-circle fa-stack-2x"></i>
                                <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                            </span>
                        </a>
                    </li>
                

                </ul>
                <!-- <p class="copyright text-muted">
                    Copyright &copy; Steve Universe 2022 
                    <br>
                    Theme by <a target="_blank" rel="noopener" href="http://huangxuan.me">Hux</a> 
                    <span style="display: inline-block; margin: 0 5px;">
                        <i class="fa fa-heart"></i>
                    </span> 
                    Ported by <a target="_blank" rel="noopener" href="http://blog.kaijun.rocks">Kaijun</a> | 
                    <iframe
                        style="margin-left: 2px; margin-bottom:-5px;"
                        frameborder="0" scrolling="0" width="91px" height="20px"
                        src="https://ghbtns.com/github-btn.html?user=kaijun&repo=hexo-theme-huxblog&type=star&count=true" >
                    </iframe>
                </p> -->
            </div>
        </div>
    </div>
</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/hux-blog.min.js"></script>



<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>

<!-- 
     Because of the native support for backtick-style fenced code blocks 
     right within the Markdown is landed in Github Pages, 
     From V1.6, There is no need for Highlight.js, 
     so Huxblog drops it officially.

     - https://github.com/blog/2100-github-pages-now-faster-and-simpler-with-jekyll-3-0  
     - https://help.github.com/articles/creating-and-highlighting-code-blocks/    
-->
<!--
    <script>
        async("http://cdn.bootcss.com/highlight.js/8.6/highlight.min.js", function(){
            hljs.initHighlightingOnLoad();
        })
    </script>
    <link href="http://cdn.bootcss.com/highlight.js/8.6/styles/github.min.css" rel="stylesheet">
-->


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("https://nhuantdbk.github.io/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->


<script>
    // dynamic User by Hux
    var _gaId = 'G-BFC0PXTRRT';
    var _gaDomain = 'nhuantdbk.github.io';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>




<!-- Side Catalog -->





<!-- Image to hack wechat -->
<img src="https://nhuantdbk.github.io/img/icon_wechat.png" width="0" height="0" />
<!-- Migrate from head to bottom, no longer block render and still work -->

</body>

</html>
